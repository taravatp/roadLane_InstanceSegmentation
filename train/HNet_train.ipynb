{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HNet_train.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPVD+vS0ecR2nwhfub/ht+S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/taravatp/roadLane_InstanceSegmentation/blob/main/train/HNet_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myFm2gzfTAXo"
      },
      "source": [
        "# Install required packages and import them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDW2UzdKSmsc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afb9a75a-015c-41ad-b923-1d8afa824f57"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AArfjujcSsxe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c67121be-54ec-46bf-cbb0-9829bdc51f2c"
      },
      "source": [
        "cd drive/MyDrive/Lane_Detection/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Lane_Detection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sv2gEwKS14Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10051739-a39a-4b60-fd3e-9b694e5f9b0e"
      },
      "source": [
        "!pip install import_ipynb "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting import_ipynb\n",
            "  Downloading import-ipynb-0.1.3.tar.gz (4.0 kB)\n",
            "Building wheels for collected packages: import-ipynb\n",
            "  Building wheel for import-ipynb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for import-ipynb: filename=import_ipynb-0.1.3-py3-none-any.whl size=2975 sha256=46551ebae1b5b849a7e4d03958bc42b88299765b7c50a20b9b3d7b59877dfb04\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/5e/dc/79780689896a056199b0b9f24471e3ee184fbd816df355d5f0\n",
            "Successfully built import-ipynb\n",
            "Installing collected packages: import-ipynb\n",
            "Successfully installed import-ipynb-0.1.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jS37l7l5THwP"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os.path as ops\n",
        "import time\n",
        "import import_ipynb\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from dataset.dataset_Hnet import HNet_dataset\n",
        "from models.Hnet import Hnet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0nBoMDhTLBE"
      },
      "source": [
        "# Hnet Loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfdIPCZuS2Qw"
      },
      "source": [
        "class HNet_loss(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(HNet_loss,self).__init__()\n",
        "\n",
        "  def forward(self,gt_points, predicted_coef):\n",
        "    batch_size = predicted_coef.shape[0]\n",
        "    hnet_loss = torch.tensor(0.).to(device)\n",
        "    for dimen in range(batch_size):\n",
        "      hnet_loss += self.hnet_loss(gt_points,predicted_coef)\n",
        "    return hnet_loss/batch_size;\n",
        "  \n",
        "  def hnet_loss(self,gt_points,predicted_coef):\n",
        "\n",
        "    gt_points = gt_points.view(-1,3)\n",
        "    predicted_coef = predicted_coef.view(6).to(device)\n",
        "\n",
        "    #creating H matrix\n",
        "    predicted_coef = torch.cat([predicted_coef, torch.tensor([1.0]).to(device)])\n",
        "    H_indices = torch.tensor([0, 1, 2, 4, 5, 7, 8], dtype=torch.long).to(device)\n",
        "    H = torch.zeros(9, dtype=torch.float32).to(device)\n",
        "    H = H.scatter_(0, H_indices, predicted_coef)\n",
        "    H = H.view(3,3).to(device)\n",
        "    \n",
        "    #calculating H*gt_points\n",
        "    gt_points = gt_points.to(torch.float32).t() #transposes the tensor \n",
        "    projected_points = torch.mm(H,gt_points) #matrix multiplication\n",
        "\n",
        "    projected_X = projected_points[0,:].view(-1,1) #putting x indices in a vector\n",
        "    projected_Y = projected_points[1,:].view(-1,1) #putting y indices in a vector\n",
        "\n",
        "    #careting Y matirx\n",
        "    Y_matrix = torch.cat([torch.pow(projected_Y,3), torch.pow(projected_Y,2), projected_Y,torch.ones_like(projected_Y,dtype=torch.float32)],dim=1)\n",
        "    #calculating w\n",
        "    w = torch.mm(Y_matrix.t(),Y_matrix).inverse().mm(Y_matrix.t()).mm(projected_X)\n",
        "    \n",
        "    #predicted x\n",
        "    x_pred = torch.mm(Y_matrix, w)  # (n * 1)\n",
        "    #predicted x and y\n",
        "    predicted_points = torch.cat([x_pred, projected_Y, torch.ones_like(projected_Y, dtype=torch.float32)], dim=1).t()  # (3 * n)\n",
        "    #reproject\n",
        "    reprojected_points = torch.mm(H.inverse(), predicted_points)\n",
        "    #calculate loss usin mean squared error\n",
        "\n",
        "    loss = torch.mean(torch.pow(reprojected_points[0, :] - predicted_points[0, :], 2))\n",
        "    return loss;\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DjzYahzRHpU"
      },
      "source": [
        "train_set = HNet_dataset('train')\n",
        "batch_size = 1\n",
        "data_loader_train = DataLoader(train_set, batch_size = batch_size, shuffle=True, num_workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qo2QGLxwRj1m"
      },
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "Hnet_model = Hnet()\n",
        "Hnet_model.to(device)\n",
        "\n",
        "learning_rate = 5e-2\n",
        "params = [p for p in Hnet_model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.Adam(params, lr=learning_rate, weight_decay=0.0002)\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "loss_function = HNet_loss()\n",
        "num_epochs = 200"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-_6P4WN-Tong",
        "outputId": "2d18a2e8-5b84-42d7-9049-a67346d8ae35"
      },
      "source": [
        "Hnet_loss = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  Hnet_model.train()\n",
        "  ts = time.time()\n",
        "  for iter,batch in enumerate(data_loader_train):\n",
        "\n",
        "    gt_image = Variable(batch[0]).to(device)\n",
        "    gt_points = Variable(batch[1]).to(device)\n",
        "\n",
        "    predicted_coef = Hnet_model(gt_image)\n",
        "    loss = loss_function(gt_points = gt_points ,predicted_coef = predicted_coef)\n",
        "    Hnet_loss.append(loss.item())\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if iter%400 == 0:\n",
        "      print(\"epoch={} , iter= {} , Hnet_loss={}\".format(epoch,iter,loss))\n",
        "\n",
        "  lr_scheduler.step()\n",
        "  print(\"Finish epoch[{}], time elapsed[{}]\".format(epoch, time.time() - ts))\n",
        "  torch.save(Hnet_model.state_dict(), f\"Hnet_model{epoch}_batch_{batch_size}.pth\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch=0 , iter= 0 , Hnet_loss=1725.78173828125\n",
            "epoch=0 , iter= 400 , Hnet_loss=268203.3125\n",
            "epoch=0 , iter= 800 , Hnet_loss=6836.052734375\n",
            "epoch=0 , iter= 1200 , Hnet_loss=8934.931640625\n",
            "epoch=0 , iter= 1600 , Hnet_loss=46098.4140625\n",
            "epoch=0 , iter= 2000 , Hnet_loss=81639.1015625\n",
            "epoch=0 , iter= 2400 , Hnet_loss=66239.84375\n",
            "epoch=0 , iter= 2800 , Hnet_loss=457700.4375\n",
            "Finish epoch[0], time elapsed[741.2354283332825]\n",
            "epoch=1 , iter= 0 , Hnet_loss=153299.390625\n",
            "epoch=1 , iter= 400 , Hnet_loss=38501.30859375\n",
            "epoch=1 , iter= 800 , Hnet_loss=235405.328125\n",
            "epoch=1 , iter= 1200 , Hnet_loss=84836.6953125\n",
            "epoch=1 , iter= 1600 , Hnet_loss=91342.3515625\n",
            "epoch=1 , iter= 2000 , Hnet_loss=1231982.125\n",
            "epoch=1 , iter= 2400 , Hnet_loss=156422.59375\n",
            "epoch=1 , iter= 2800 , Hnet_loss=255593.75\n",
            "Finish epoch[1], time elapsed[65.91449451446533]\n",
            "epoch=2 , iter= 0 , Hnet_loss=303280.78125\n",
            "epoch=2 , iter= 400 , Hnet_loss=283174.28125\n",
            "epoch=2 , iter= 800 , Hnet_loss=3841664.75\n",
            "epoch=2 , iter= 1200 , Hnet_loss=119427.8671875\n",
            "epoch=2 , iter= 1600 , Hnet_loss=82994.515625\n",
            "epoch=2 , iter= 2000 , Hnet_loss=189871.078125\n",
            "epoch=2 , iter= 2400 , Hnet_loss=117524.2265625\n",
            "epoch=2 , iter= 2800 , Hnet_loss=489381.6875\n",
            "Finish epoch[2], time elapsed[65.4398603439331]\n",
            "epoch=3 , iter= 0 , Hnet_loss=326888.90625\n",
            "epoch=3 , iter= 400 , Hnet_loss=8739253.0\n",
            "epoch=3 , iter= 800 , Hnet_loss=403312.03125\n",
            "epoch=3 , iter= 1200 , Hnet_loss=3774036.5\n",
            "epoch=3 , iter= 1600 , Hnet_loss=97083.421875\n",
            "epoch=3 , iter= 2000 , Hnet_loss=34609.25\n",
            "epoch=3 , iter= 2400 , Hnet_loss=6010311.5\n",
            "epoch=3 , iter= 2800 , Hnet_loss=2512393.5\n",
            "Finish epoch[3], time elapsed[65.05694723129272]\n",
            "epoch=4 , iter= 0 , Hnet_loss=1583693.125\n",
            "epoch=4 , iter= 800 , Hnet_loss=921282.625\n",
            "epoch=4 , iter= 1200 , Hnet_loss=37068.296875\n",
            "epoch=4 , iter= 1600 , Hnet_loss=720203.0625\n",
            "epoch=4 , iter= 2000 , Hnet_loss=79984.9921875\n",
            "epoch=4 , iter= 2400 , Hnet_loss=60532.8984375\n",
            "epoch=4 , iter= 2800 , Hnet_loss=12041560.0\n",
            "Finish epoch[4], time elapsed[65.5806884765625]\n",
            "epoch=5 , iter= 0 , Hnet_loss=5863023.5\n",
            "epoch=5 , iter= 400 , Hnet_loss=876437.4375\n",
            "epoch=5 , iter= 800 , Hnet_loss=20935294.0\n",
            "epoch=5 , iter= 1200 , Hnet_loss=9044811.0\n",
            "epoch=5 , iter= 1600 , Hnet_loss=4106355.75\n",
            "epoch=5 , iter= 2000 , Hnet_loss=3829762.75\n",
            "epoch=5 , iter= 2400 , Hnet_loss=477850.875\n",
            "epoch=5 , iter= 2800 , Hnet_loss=1543818.75\n",
            "Finish epoch[5], time elapsed[65.30261826515198]\n",
            "epoch=6 , iter= 0 , Hnet_loss=393225.71875\n",
            "epoch=6 , iter= 400 , Hnet_loss=2767507.5\n",
            "epoch=6 , iter= 800 , Hnet_loss=47598008.0\n",
            "epoch=6 , iter= 1200 , Hnet_loss=37098264.0\n",
            "epoch=6 , iter= 1600 , Hnet_loss=29155862.0\n",
            "epoch=6 , iter= 2000 , Hnet_loss=12790450.0\n",
            "epoch=6 , iter= 2400 , Hnet_loss=394443.09375\n",
            "epoch=6 , iter= 2800 , Hnet_loss=1159889.75\n",
            "Finish epoch[6], time elapsed[64.96208834648132]\n",
            "epoch=7 , iter= 0 , Hnet_loss=2998444.75\n",
            "epoch=7 , iter= 400 , Hnet_loss=2098529.75\n",
            "epoch=7 , iter= 800 , Hnet_loss=609771.8125\n",
            "epoch=7 , iter= 1200 , Hnet_loss=5713448.0\n",
            "epoch=7 , iter= 1600 , Hnet_loss=1884046.25\n",
            "epoch=7 , iter= 2000 , Hnet_loss=294571.875\n",
            "epoch=7 , iter= 2400 , Hnet_loss=4779436.0\n",
            "epoch=7 , iter= 2800 , Hnet_loss=4894412.5\n",
            "Finish epoch[7], time elapsed[65.18346333503723]\n",
            "epoch=8 , iter= 0 , Hnet_loss=137800.734375\n",
            "epoch=8 , iter= 400 , Hnet_loss=3500331.25\n",
            "epoch=8 , iter= 800 , Hnet_loss=337132.0625\n",
            "epoch=8 , iter= 1200 , Hnet_loss=46855188.0\n",
            "epoch=8 , iter= 1600 , Hnet_loss=2311128.25\n",
            "epoch=8 , iter= 2000 , Hnet_loss=1378333.0\n",
            "epoch=8 , iter= 2400 , Hnet_loss=1125948.25\n",
            "epoch=8 , iter= 2800 , Hnet_loss=5288013.5\n",
            "Finish epoch[8], time elapsed[65.10569095611572]\n",
            "epoch=9 , iter= 0 , Hnet_loss=8260902.5\n",
            "epoch=9 , iter= 400 , Hnet_loss=1712586.375\n",
            "epoch=9 , iter= 800 , Hnet_loss=71191.890625\n",
            "epoch=9 , iter= 1200 , Hnet_loss=298549.25\n",
            "epoch=9 , iter= 1600 , Hnet_loss=1012173.0625\n",
            "epoch=9 , iter= 2000 , Hnet_loss=397764.78125\n",
            "epoch=9 , iter= 2400 , Hnet_loss=3050.783203125\n",
            "epoch=9 , iter= 2800 , Hnet_loss=5313411.0\n",
            "Finish epoch[9], time elapsed[66.99273443222046]\n",
            "epoch=10 , iter= 0 , Hnet_loss=92120152.0\n",
            "epoch=10 , iter= 400 , Hnet_loss=110922776.0\n",
            "epoch=10 , iter= 800 , Hnet_loss=59389260.0\n",
            "epoch=10 , iter= 1200 , Hnet_loss=26236636.0\n",
            "epoch=10 , iter= 1600 , Hnet_loss=24814372.0\n",
            "epoch=10 , iter= 2000 , Hnet_loss=11804758.0\n",
            "epoch=10 , iter= 2400 , Hnet_loss=1504930.625\n",
            "epoch=10 , iter= 2800 , Hnet_loss=nan\n",
            "Finish epoch[10], time elapsed[65.0927345752716]\n",
            "epoch=11 , iter= 0 , Hnet_loss=nan\n",
            "epoch=11 , iter= 400 , Hnet_loss=nan\n",
            "epoch=11 , iter= 800 , Hnet_loss=nan\n",
            "epoch=11 , iter= 1200 , Hnet_loss=nan\n",
            "epoch=11 , iter= 1600 , Hnet_loss=nan\n",
            "epoch=11 , iter= 2000 , Hnet_loss=nan\n",
            "epoch=11 , iter= 2400 , Hnet_loss=nan\n",
            "epoch=11 , iter= 2800 , Hnet_loss=nan\n",
            "Finish epoch[11], time elapsed[64.9110655784607]\n",
            "epoch=12 , iter= 0 , Hnet_loss=nan\n",
            "epoch=12 , iter= 400 , Hnet_loss=nan\n",
            "epoch=12 , iter= 800 , Hnet_loss=nan\n",
            "epoch=12 , iter= 1200 , Hnet_loss=nan\n",
            "epoch=12 , iter= 1600 , Hnet_loss=nan\n",
            "epoch=12 , iter= 2000 , Hnet_loss=nan\n",
            "epoch=12 , iter= 2400 , Hnet_loss=nan\n",
            "epoch=12 , iter= 2800 , Hnet_loss=nan\n",
            "Finish epoch[12], time elapsed[64.92263269424438]\n",
            "epoch=13 , iter= 0 , Hnet_loss=nan\n",
            "epoch=13 , iter= 400 , Hnet_loss=nan\n",
            "epoch=13 , iter= 800 , Hnet_loss=nan\n",
            "epoch=13 , iter= 1200 , Hnet_loss=nan\n",
            "epoch=13 , iter= 1600 , Hnet_loss=nan\n",
            "epoch=13 , iter= 2000 , Hnet_loss=nan\n",
            "epoch=13 , iter= 2400 , Hnet_loss=nan\n",
            "epoch=13 , iter= 2800 , Hnet_loss=nan\n",
            "Finish epoch[13], time elapsed[65.14725160598755]\n",
            "epoch=14 , iter= 0 , Hnet_loss=nan\n",
            "epoch=14 , iter= 400 , Hnet_loss=nan\n",
            "epoch=14 , iter= 800 , Hnet_loss=nan\n",
            "epoch=14 , iter= 1200 , Hnet_loss=nan\n",
            "epoch=14 , iter= 1600 , Hnet_loss=nan\n",
            "epoch=14 , iter= 2000 , Hnet_loss=nan\n",
            "epoch=14 , iter= 2400 , Hnet_loss=nan\n",
            "epoch=14 , iter= 2800 , Hnet_loss=nan\n",
            "Finish epoch[14], time elapsed[65.70398879051208]\n",
            "epoch=15 , iter= 0 , Hnet_loss=nan\n",
            "epoch=15 , iter= 400 , Hnet_loss=nan\n",
            "epoch=15 , iter= 800 , Hnet_loss=nan\n",
            "epoch=15 , iter= 1200 , Hnet_loss=nan\n",
            "epoch=15 , iter= 1600 , Hnet_loss=nan\n",
            "epoch=15 , iter= 2000 , Hnet_loss=nan\n",
            "epoch=15 , iter= 2400 , Hnet_loss=nan\n",
            "Finish epoch[15], time elapsed[64.98180174827576]\n",
            "epoch=16 , iter= 0 , Hnet_loss=nan\n",
            "epoch=16 , iter= 400 , Hnet_loss=nan\n",
            "epoch=16 , iter= 800 , Hnet_loss=nan\n",
            "epoch=16 , iter= 1200 , Hnet_loss=nan\n",
            "epoch=16 , iter= 1600 , Hnet_loss=nan\n",
            "epoch=16 , iter= 2000 , Hnet_loss=nan\n",
            "epoch=16 , iter= 2400 , Hnet_loss=nan\n",
            "epoch=16 , iter= 2800 , Hnet_loss=nan\n",
            "Finish epoch[16], time elapsed[65.0754542350769]\n",
            "epoch=17 , iter= 0 , Hnet_loss=nan\n",
            "epoch=17 , iter= 400 , Hnet_loss=nan\n",
            "epoch=17 , iter= 800 , Hnet_loss=nan\n",
            "epoch=17 , iter= 1200 , Hnet_loss=nan\n",
            "epoch=17 , iter= 1600 , Hnet_loss=nan\n",
            "epoch=17 , iter= 2000 , Hnet_loss=nan\n",
            "epoch=17 , iter= 2400 , Hnet_loss=nan\n",
            "epoch=17 , iter= 2800 , Hnet_loss=nan\n",
            "Finish epoch[17], time elapsed[65.33154034614563]\n",
            "epoch=18 , iter= 0 , Hnet_loss=nan\n",
            "epoch=18 , iter= 400 , Hnet_loss=nan\n",
            "epoch=18 , iter= 800 , Hnet_loss=nan\n",
            "epoch=18 , iter= 1200 , Hnet_loss=nan\n",
            "epoch=18 , iter= 1600 , Hnet_loss=nan\n",
            "epoch=18 , iter= 2000 , Hnet_loss=nan\n",
            "epoch=18 , iter= 2400 , Hnet_loss=nan\n",
            "epoch=18 , iter= 2800 , Hnet_loss=nan\n",
            "Finish epoch[18], time elapsed[64.8164575099945]\n",
            "epoch=19 , iter= 0 , Hnet_loss=nan\n",
            "epoch=19 , iter= 400 , Hnet_loss=nan\n",
            "epoch=19 , iter= 800 , Hnet_loss=nan\n",
            "epoch=19 , iter= 1200 , Hnet_loss=nan\n",
            "epoch=19 , iter= 1600 , Hnet_loss=nan\n",
            "epoch=19 , iter= 2000 , Hnet_loss=nan\n",
            "epoch=19 , iter= 2400 , Hnet_loss=nan\n",
            "epoch=19 , iter= 2800 , Hnet_loss=nan\n",
            "Finish epoch[19], time elapsed[66.11853003501892]\n",
            "epoch=20 , iter= 0 , Hnet_loss=nan\n",
            "epoch=20 , iter= 400 , Hnet_loss=nan\n",
            "epoch=20 , iter= 800 , Hnet_loss=nan\n",
            "epoch=20 , iter= 1200 , Hnet_loss=nan\n",
            "epoch=20 , iter= 1600 , Hnet_loss=nan\n",
            "epoch=20 , iter= 2000 , Hnet_loss=nan\n",
            "epoch=20 , iter= 2800 , Hnet_loss=nan\n",
            "Finish epoch[20], time elapsed[64.58381581306458]\n",
            "epoch=21 , iter= 0 , Hnet_loss=nan\n",
            "epoch=21 , iter= 400 , Hnet_loss=nan\n",
            "epoch=21 , iter= 800 , Hnet_loss=nan\n",
            "epoch=21 , iter= 1200 , Hnet_loss=nan\n",
            "epoch=21 , iter= 1600 , Hnet_loss=nan\n",
            "epoch=21 , iter= 2000 , Hnet_loss=nan\n",
            "epoch=21 , iter= 2400 , Hnet_loss=nan\n",
            "epoch=21 , iter= 2800 , Hnet_loss=nan\n",
            "Finish epoch[21], time elapsed[64.60540580749512]\n",
            "epoch=22 , iter= 0 , Hnet_loss=nan\n",
            "epoch=22 , iter= 400 , Hnet_loss=nan\n",
            "epoch=22 , iter= 800 , Hnet_loss=nan\n",
            "epoch=22 , iter= 1200 , Hnet_loss=nan\n",
            "epoch=22 , iter= 1600 , Hnet_loss=nan\n",
            "epoch=22 , iter= 2000 , Hnet_loss=nan\n",
            "epoch=22 , iter= 2400 , Hnet_loss=nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-62b462d48899>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m400\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    147\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "qrzYcDbPVmcj",
        "outputId": "9d984efb-08a2-4aba-b646-1291fe045906"
      },
      "source": [
        "import matplotlib.pylab as plt\n",
        "%matplotlib inline\n",
        "plt.title('loss over iterations')\n",
        "plt.xlabel('iterations')\n",
        "plt.ylabel('loss')\n",
        "plt.plot(Hnet_loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fa651f6c290>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLIGcgLMiwK_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "6373d75e-b3a2-4eee-b902-c9a2b09a181e"
      },
      "source": [
        "import matplotlib.pylab as plt\n",
        "%matplotlib inline\n",
        "plt.title('loss over iterations')\n",
        "plt.xlabel('iterations')\n",
        "plt.ylabel('loss')\n",
        "plt.plot(Hnet_loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f71cb656490>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAbqElEQVR4nO3de5hV1Z3m8e/LVQUElDIiIoiiiWbaGxqdxMTJpL21E3u6TdROx0vSw7RPzKVjOqMmj7GdpNuM3UnG1sRgdNS00aQ1GjrB68RE0xG0YBBBRErEAHIpQbmKUPCbP/YqPFWculq7ThXr/TzPedhn73X2Xntz6rxnr7XP2ooIzMwsXwNqXQEzM6stB4GZWeYcBGZmmXMQmJllzkFgZpY5B4GZWeYcBNZrJC2V9LFa16NskjZJmlTD7Z8qaVGttm/9j4PArIdFxPCIWAIg6Q5J3yxze5JC0uEV238qIo4sc5u2Z3EQmHWTpEF7wjbMHARWE5KGSvqepNfS43uShqZlYyT9UtKbktZJekrSgLTsf0haIWmjpEWS/nMb6x8p6S5JjZJelfR1SQPSdt+U9P6KsnWS3pJ0QHp+jqS5qdzvJf1RRdmlqQ7zgM3VPqibv6FLmgp8Cvhqai76t7T8IEn3p7q9IukLFa+9VtJ9kv5F0gbgEkknSXo61WelpJskDUnln0wvfS5t43xJp0laXrHO90n6TXr9Akkfr1h2h6SbJf0qHdNZkg5LyyTpu5LWSNog6fnK42Z7kIjww49eeQBLgY+l6euAmcABQB3we+B/pmX/ANwCDE6PUwEBRwLLgINSuYnAYW1s6y7gF8CIVO4l4LNp2e3AtyrKfg54OE0fB6wBPgAMBC5O9R5asQ9zgfHA3m1sO4DD0/QdwDcrlg0AZgPXAEOAScAS4Iy0/FpgO/CnqezewAnAycCgtC8LgS9V2156fhqwPE0PBhqAq9P2PgpsBI6sqN9a4KS0/ruBe9OyM1JdR6Xj/z5gbK3fR370/KNfnhFIuj19S5nfibIfljRHUpOk8yrmH5u+ZS2QNE/S+eXW2lr5FHBdRKyJiEbg74BPp2XbgbHAhIjYHkWbdwA7gKHAUZIGR8TSiHi59YolDQQuAK6KiI0RsRT4p4r1/yQtb/YXaR7AVOCHETErInZExJ3A2xQfxM1ujIhlEfFWN/b7RKAuIq6LiG1R9CXc2qo+T0fEgxGxMyLeiojZETEzIprSvvwQ+Egnt3cyMBy4Pm3v18AvgQsryjwQEc9ERBNFEByb5m+nCNL3AoqIhRGxshv7bH1cvwwCim8xZ3ay7B+AS3jnD73ZFuCiiDg6ret7kkb1VAWtQwcBr1Y8fzXNA7iB4lvso5KWSLoSICIagC9RfGteI+leSQexuzEU34Rbr39cmn4C2EfSByRNpPjgeyAtmwBckZpR3pT0JsW3/8rtLOv67u4yATio1fqvBt7T1volHZGaylal5qK/T/vYGQcByyJiZ8W8ymMBsKpiegtFcJBC4ybgZorjPU3Svp3crvUj/TIIIuJJYF3lPEmHSXpY0uzUpvzeVHZpRMwDdrZax0sRsThNv0bRHFDXO3tgwGsUH4rNDknzSN/ir4iIScDHgS839wVExE8i4kPptQF8u8q6X6f4Ntt6/SvSOnYAP6P4Vnwh8MuI2JjKLaNoNhpV8dgnIu6pWFdXhuxtXXYZ8Eqr9Y+IiLPbec0PgBeByRGxL0VwqJPbfw0Y39zHkuw6Fh1WPuLGiDgBOAo4AvjbTm7X+pF+GQRtmAZ8Pr1pvwJ8v7MvlHQSRfvpbs0MVpp7gK+njtoxFG3m/wK7OmsPlyRgPUWT0E5JR0r6aOpU3gq8RauAhxYf9N+SNELSBODLzetPfgKcT9FEVXm2eCvw1+lsQZKGSfoTSSO6uZ+rKfoBmj0DbEwdzntLGijp/ZJObGcdI4ANwKb0BeeyDrZRaRbFt/yvShos6TTgvwD3dlRxSSem4zAY2ExxzHc73tb/7RFBIGk48B+Bf5U0l6INdWwnXzsW+DFwaavTZyvXN4F6YB7wPDAnzQOYDDwObAKeBr4fEU9Q9A9cT/GNfxVFR/NVbaz/8xQfXkuA31F82N/evDAiZqXlBwEPVcyvB/4bRZPIGxRNVJe8i/28jaJP401JD6aQOoeiOeqVtC8/Aka2s46vUPRjbKQIqp+2Wn4tcGfaxicrF0TENooP/rPStr5P0ST6Yifqvm/a3hsUzUlrKZrtbA+jog+u/0ltu7+MiPendstFEdHmh7+kO1L5+yrm7Qv8Bvj7yvlmZjnZI84IImID8IqkT8Cu65+Pae816TrsB4C7HAJmlrN+eUYg6R6Ka6XHULSPfgP4NUWn2liKK0bujYjrUtvrA8BoijbOVRFxtKS/BP4PsKBi1ZdExNxe2xEzsz6gXwaBmZn1nD2iacjMzLqv3w1oNWbMmJg4cWKtq2Fm1q/Mnj379Yio+lupfhcEEydOpL6+vtbVMDPrVyS92tYyNw2ZmWXOQWBmlrnSgkDSeElPSHohjfD5xSplTpO0XsXY73MlXVNWfczMrLoy+wiagCsiYk4ap2W2pMci4oVW5Z6KiHNKrIeZmbWjtDOCiFgZEXPS9EaKm2mMa/9VZmbW23qljyCNC3QcxUiIrZ0i6TlJD0k6uo3XT5VUL6m+sbGxxJqameWn9CBII4PeT3FrvQ2tFs+huAvVMcA/Aw9WW0dETIuIKRExpa7OtwwwM+tJpQZBGsf8fuDuiPh56+URsSEiNqXpGcDgNDa9mfWAWUvWsnj1xo4LWtbKvGpIFGOxL4yI77RR5sBUrvnmMAMoxjw3sx5w/rSZ/PF3n6x1NayPK/OqoQ9S3Cz8+XSzGChusXcIQETcApwHXCapieJuUxeER8EzM+tVpQVBRPyODu6rGhE3UdwJyszMasS/LDYzy5yDwMwscw4CM7PMOQjMzDLnIDAzy5yDwMwscw4CM7PMOQjMzDLnIDAzy5yDwMwscw4CM7PMOQjMzDLnIDAzy5yDwMwscw4CM7PMOQjMzDLnIDAzy5yDwMwscw4CM7PMOQjMzDLnIDAzy5yDwMwscw4CM7PMOQjMzDLnIDAzy5yDwMwscw4CM7PMOQjMzDLnIDAzy5yDwMwscw4CM7PMlRYEksZLekLSC5IWSPpilTKSdKOkBknzJB1fVn3MzKy6QSWuuwm4IiLmSBoBzJb0WES8UFHmLGByenwA+EH618zMeklpZwQRsTIi5qTpjcBCYFyrYucCd0VhJjBK0tiy6mRmZrvrlT4CSROB44BZrRaNA5ZVPF/O7mGBpKmS6iXVNzY2llVNM7MslR4EkoYD9wNfiogN3VlHREyLiCkRMaWurq5nK2hmlrlSg0DSYIoQuDsifl6lyApgfMXzg9M8MzPrJWVeNSTgNmBhRHynjWLTgYvS1UMnA+sjYmVZdTIzs92VedXQB4FPA89LmpvmXQ0cAhARtwAzgLOBBmALcGmJ9TEzsypKC4KI+B2gDsoE8Lmy6mBmZh3zL4vNzDLnIDAzy5yDwMwscw4CM7PMOQjMzDLnIDAzy5yDwMwscw4CM7PMOQjMzDLnIDAzy5yDwMwscw4CM7PMOQjMzDLnIDAzy5yDwMwscw4CM7PMOQjMzDLnIDAzy5yDwMwscw4CM7PMOQjMzDLnIDAzy5yDwMwscw4CM7PMOQjMzDLnIDAzy5yDwMwscw4CM7PMOQjMzDLnIDAzy5yDwMwsc6UFgaTbJa2RNL+N5adJWi9pbnpcU1ZdzMysbYNKXPcdwE3AXe2UeSoizimxDmZm1oHSzggi4klgXVnrNzOznlHrPoJTJD0n6SFJR7dVSNJUSfWS6hsbG3uzfmZme7xaBsEcYEJEHAP8M/BgWwUjYlpETImIKXV1db1WQTOzHNQsCCJiQ0RsStMzgMGSxtSqPmZmuapZEEg6UJLS9EmpLmtrVR8zs1yVdtWQpHuA04AxkpYD3wAGA0TELcB5wGWSmoC3gAsiIsqqj5mZVVdaEETEhR0sv4ni8lIzM6uhWl81ZGZmNeYgMDPLnIPAzCxzDgIzs8w5CMzMMucgMDPLnIPAzCxzDgIzs8w5CMzMMucgMDPLXKeCQNIXJe2rwm2S5kg6vezKmZlZ+Tp7RvCZiNgAnA6MBj4NXF9arczMrNd0NgiU/j0b+HFELKiYZ2Zm/Vhng2C2pEcpguARSSOAneVVy8zMektnh6H+LHAssCQitkjaD7i0vGqZmVlv6ewZwSnAooh4U9JfAl8H1pdXLTMz6y2dDYIfAFskHQNcAbwM3FVarczMrNd0Ngia0m0kzwVuioibgRHlVcvMzHpLZ/sINkq6iuKy0VMlDSDdf9jMzPq3zp4RnA+8TfF7glXAwcANpdXKzMx6TaeCIH343w2MlHQOsDUi3EdgZrYH6OwQE58EngE+AXwSmCXpvDIrZmZmvaOzfQRfA06MiDUAkuqAx4H7yqqYmZn1js72EQxoDoFkbRdea2ZmfVhnzwgelvQIcE96fj4wo5wqmZlZb+pUEETE30r6c+CDada0iHigvGqZmVlv6ewZARFxP3B/iXUxM7MaaDcIJG0EotoiICJi31JqZWZmvabdIIgIDyNhZraH85U/ZmaZyyYIIoJbn1zC+i3ba10VM7M+pbQgkHS7pDWS5rexXJJulNQgaZ6k48uqC8DMJev41oyFXP3A82Vuxsys3ynzjOAO4Mx2lp8FTE6PqRT3PCjNth3FnTU3bPUZgZlZpdKCICKeBNa1U+Rc4K4ozARGSRpbVn3MzKy6WvYRjAOWVTxfnuaZmVkv6hedxZKmSqqXVN/Y2Ni9dfRwnczM9hS1DIIVwPiK5wenebuJiGkRMSUiptTV1fVK5czMclHLIJgOXJSuHjoZWB8RK2tYHzOzLHV6rKGuknQPcBowRtJy4Buk+xxHxC0Uo5eeDTQAW4BLy6pLpag2YIaZWcZKC4KIuLCD5QF8rqzttyZ3EpiZVdUvOovNzKw82QVBVB1M1cwsX9kEgXwBqZlZVdkEgZmZVZddEPiqITOzlrILAjMzaymbIPDlo2bVfeaOZ/lP//ibWlfDaqi03xGYWf/w6xfX1LoKVmPZnBE0cx+BmVlL2QSBW4bMzKrLJgjMzKy67ILAvyw2M2spuyAwM7OW8gkCdxKYmVWVTxCYmVlV2QWBLx81M2spmyDw6KNmZtVlEwRmZlZddkHgliEzs5ayCwIzM2spuyBwT4GZWUvZBYGZmbWUXRC4j8DMrKVsgsA3pjEzqy6bIDAzs+ryCwK3DZmZtZBfEJiZWQvZBIG7CMzMqssmCMzMrLrsgsB3KDMzaymbIJCvHzUzqyqbIDAzs+pKDQJJZ0paJKlB0pVVll8iqVHS3PT4qzLrA74xjZlZa4PKWrGkgcDNwB8Dy4FnJU2PiBdaFf1pRFxeVj3MzKx9ZZ4RnAQ0RMSSiNgG3AucW+L22uUuAjOz6soMgnHAsorny9O81v5c0jxJ90kaX21FkqZKqpdU39jYWEZdzcyyVevO4n8DJkbEHwGPAXdWKxQR0yJiSkRMqaure1cbdBeBmVlLZQbBCqDyG/7Bad4uEbE2It5OT38EnFBWZdwyZGZWXZlB8CwwWdKhkoYAFwDTKwtIGlvx9OPAwhLrY2ZmVZR21VBENEm6HHgEGAjcHhELJF0H1EfEdOALkj4ONAHrgEvKqk9FvcrehJlZv1JaEABExAxgRqt511RMXwVcVWYdzMysfbXuLO41vnzUzKy6bILAzMyqyy4I3ENgZtZSRkHgtiEzs2oyCgIzM6vGQWBmljkHgZlZ5hwEZmaZyy4I/MNiM7OWsgsCMzNrKZsg8C+LzcyqyyYIzMysuuyCwF0EZmYtZRMEbhkyM6sumyAwM7Pq8gsCXz9qZtZCfkFgZmYtZBME8vWjZmZVZRMEZmZWXXZB4B4CM7OWsgkCNwyZmVWXTRCYmVl12QWBrx41M2spuyDI2cwla3n65bW1roaZ9THZBEFfuXr0Z88u4xO3/L4m275g2kwuvHVmTbZtZn3XoFpXIDdfvX9eratgZtZCNmcEzcIXkJqZtZBNEMgXkJqZVZVNEORm/or1TLzyV7zw2oZaV8XM+rjsgiCXy0cfXbAKgMdeWF3jmphZX5ddEPQVO3eWm0gDBxT/tTt27ix1O2bW/5UaBJLOlLRIUoOkK6ssHyrpp2n5LEkTy6tLWWvunh0ln5oMGljscFOVwHlr245St23WnzSs2UiU8Pd48xMNPPPKuh5fbxlKCwJJA4GbgbOAo4ALJR3VqthngTci4nDgu8C3y6pPX7Ozgzfejp1B047uf5sfOEC71hMRvPL65l3L3nfNw51ax0PPr2TV+q27zX+7aQe3/PZltjV1vX5NO3aycev2Lr+uNz3x4hq2bi/Ccsu2JnaUfPbWF0VEj344Tn/uNbZsa+qx9fWUZ5eu42PfeZK7Z/2hR9c75w9vcMMji/jkD5/u9jrKCKe2qKyNSToFuDYizkjPrwKIiH+oKPNIKvO0pEHAKqAu2qnUlClTor6+vsv1+dFTS/jmrxYCMPmA4V1+fXs2bm1i1YatjBu1N/sMGdhu2cVrNgFwWN0wBrRzmtJcrrt1bX59Wzpa784IXm7cXLVs5bq7Wr/m1x5+wPBOXce1dO1mtu+ITpfv7Pbbqvdrb77F5nTGNPmA4e/6/6G79ejN7VQr05P1e3XtFralLzVl729bGho3MXzoIA7cd68W89/Ne7k97a137eZtbHhrO+P324dBA6q/qxsaNxEBB43ci2FD3/m51/knjuevTp3UrTpJmh0RU6otK/MHZeOAZRXPlwMfaKtMRDRJWg/sD7xeWUjSVGAqwCGHHNKtyhx3yGgAjj9kFAeO3KuD0l2zY2ewasFWJtUNY8Re7R9SCV5avYkjDxzRbrnFazYxdNAAJr+ne2/OCfsP4/GFq/nIEXUA/PalRoYMGrDrW3xn1vty42Ym1Q3breyE/ffh8YVr+MgRdQwb2n7wtbYjgiWNmzmik/s1ep8hPLN0XafLd+SV1zcjtb3/hx8wnIfmr+KY8aMYN2ovFq/ZxMGj9+72/0Nbmt8HPb3e1hav2cSIvQa1u503tmzn9U1vtyizeM0m9h82pEfq13xMjztkFGN7+G+vs4YOHsD8FRs4dXLL/ZlUN4xHFqzmlEn7M3rY4B7b3v7DhzBzyTrGjtxr97+fpuDxhas5rG44QwZVD4Lm9/1/OHjkrrN7gDHDh/ZYHSv1i18WR8Q0YBoUZwTdWccJE0az9Po/6dF6mZntCcrsLF4BjK94fnCaV7VMahoaCXhUNDOzXlRmEDwLTJZ0qKQhwAXA9FZlpgMXp+nzgF+31z9gZmY9r7SmodTmfznwCDAQuD0iFki6DqiPiOnAbcCPJTUA6yjCwszMelGpfQQRMQOY0WreNRXTW4FPlFkHMzNrn39ZbGaWOQeBmVnmHARmZplzEJiZZa60ISbKIqkReLWbLx9Dq18tZ8rHoeDj4GPQLIfjMCEi6qot6HdB8G5Iqm9rrI2c+DgUfBx8DJrlfhzcNGRmljkHgZlZ5nILgmm1rkAf4eNQ8HHwMWiW9XHIqo/AzMx2l9sZgZmZteIgMDPLXDZBIOlMSYskNUi6stb16WmSlkp6XtJcSfVp3n6SHpO0OP07Os2XpBvTsZgn6fiK9Vycyi+WdHFb2+srJN0uaY2k+RXzemy/JZ2QjmtDem1P3DGzx7VxHK6VtCK9J+ZKOrti2VVpnxZJOqNiftW/kzSc/Kw0/6dpaPk+RdJ4SU9IekHSAklfTPOzez90WfNNqvfkB8Uw2C8Dk4AhwHPAUbWuVw/v41JgTKt5/wu4Mk1fCXw7TZ8NPAQIOBmYlebvByxJ/45O06NrvW8d7PeHgeOB+WXsN/BMKqv02rNqvc9dOA7XAl+pUvao9DcwFDg0/W0MbO/vBPgZcEGavgW4rNb7XGW/xgLHp+kRwEtpX7N7P3T1kcsZwUlAQ0QsiYhtwL3AuTWuU284F7gzTd8J/GnF/LuiMBMYJWkscAbwWESsi4g3gMeAM3u70l0REU9S3MuiUo/sd1q2b0TMjOJT4K6KdfUpbRyHtpwL3BsRb0fEK0ADxd9I1b+T9K33o8B96fWVx7TPiIiVETEnTW8EFlLcFz2790NX5RIE44BlFc+Xp3l7kgAelTRb0tQ07z0RsTJNrwLek6bbOh57ynHqqf0el6Zbz+9PLk/NHrc3N4nQ9eOwP/BmRDS1mt9nSZoIHAfMwu+HDuUSBDn4UEQcD5wFfE7ShysXpm8w2V0rnOt+Jz8ADgOOBVYC/1Tb6vQOScOB+4EvRcSGymWZvx/alEsQrADGVzw/OM3bY0TEivTvGuABitP81el0lvTvmlS8reOxpxynntrvFWm69fx+ISJWR8SOiNgJ3ErxnoCuH4e1FM0mg1rN73MkDaYIgbsj4udptt8PHcglCJ4FJqcrH4ZQ3Bt5eo3r1GMkDZM0onkaOB2YT7GPzVc8XAz8Ik1PBy5KV02cDKxPp86PAKdLGp2aEU5P8/qbHtnvtGyDpJNTO/lFFevq85o//JL/SvGegOI4XCBpqKRDgckUnaBV/07St+gngPPS6yuPaZ+R/o9uAxZGxHcqFvn90JFa91b31oPiCoGXKK6K+Fqt69PD+zaJ4gqP54AFzftH0bb7f4HFwOPAfmm+gJvTsXgemFKxrs9QdB42AJfWet86se/3UDR7bKdos/1sT+43MIXiA/Rl4CbSr/H72qON4/DjtJ/zKD70xlaU/1rap0VUXPnS1t9Jeo89k47PvwJDa73PVY7BhyiafeYBc9Pj7BzfD119eIgJM7PM5dI0ZGZmbXAQmJllzkFgZpY5B4GZWeYcBGZmmXMQWHYk/T79O1HSX/Twuq+uti2zvsyXj1q2JJ1GMTrnOV14zaB4Z8ydass3RcTwnqifWW/xGYFlR9KmNHk9cGoaq/9vJA2UdIOkZ9NAbf89lT9N0lOSpgMvpHkPpgH+FjQP8ifpemDvtL67K7eVfr16g6T5aTz78yvW/RtJ90l6UdLdzWPcS7pexdj68yT9Y28eI8vLoI6LmO2xrqTijCB9oK+PiBMlDQX+XdKjqezxwPujGLYZ4DMRsU7S3sCzku6PiCslXR4Rx1bZ1p9RDP52DDAmvebJtOw44GjgNeDfgQ9KWkgxLMR7IyIkjerxvTdLfEZg9o7TKcaemUsxfPH+FOPwADxTEQIAX5D0HDCTYoCyybTvQ8A9UQwCtxr4LXBixbqXRzE43FxgIrAe2ArcJunPgC3veu/M2uAgMHuHgM9HxLHpcWhENJ8RbN5VqOhb+BhwSkQcA/w/YK93sd23K6Z3AM39ECdR3AzmHODhd7F+s3Y5CCxnGyluadjsEeCyNJQxko5Io7m2NhJ4IyK2SHovxa0Lm21vfn0rTwHnp36IOopbSz7TVsXSmPojI2IG8DcUTUpmpXAfgeVsHrAjNfHcAfxvimaZOanDtpHqtyJ8GPjr1I6/iKJ5qNk0YJ6kORHxqYr5DwCnUIwQG8BXI2JVCpJqRgC/kLQXxZnKl7u3i2Yd8+WjZmaZc9OQmVnmHARmZplzEJiZZc5BYGaWOQeBmVnmHARmZplzEJiZZe7/A/AXURZRlc5LAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNMihTlUiwQu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMyGDu8Jf1rn",
        "outputId": "f98d4949-bfe3-4775-d600-623b17bed9f4"
      },
      "source": [
        "print(learning_rate)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0005\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxJDCEJxgHWF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}