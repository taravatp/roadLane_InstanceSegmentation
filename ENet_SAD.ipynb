{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ENet_SAD.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1KPYHDU6_PR4Tltg4iY63tzYiL9NZ1D1J",
      "authorship_tag": "ABX9TyNvDn41P7KwwP2+G9QDz7Uf",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/taravatp/roadLane_InstanceSegmentation/blob/main/ENet_SAD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poScWTXPufCe"
      },
      "source": [
        "# Creating the building blocks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4NsIjW5uO0F"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.parameter import Parameter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_94QuBTuxcF"
      },
      "source": [
        "class InitialBlock(nn.Module):\n",
        "\n",
        "  def __init__(self,in_channels,out_channels,bias=False,relu=True):\n",
        "    super().__init__()\n",
        "\n",
        "    if relu:\n",
        "        activation = nn.ReLU\n",
        "    else:\n",
        "        activation = nn.PReLU \n",
        "\n",
        "    self.main_branch = nn.Conv2d(in_channels,out_channels - 3,kernel_size=3,stride=2,padding=1,bias=bias)\n",
        "    self.ext_branch = nn.MaxPool2d(3, stride=2, padding=1)\n",
        "    self.batch_norm = nn.BatchNorm2d(out_channels)\n",
        "    self.out_activation = activation()\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    main = self.main_branch(x)\n",
        "    ext = self.ext_branch(x)\n",
        "    out = torch.cat((main, ext), 1) #dim 1 is the channels\n",
        "    out = self.batch_norm(out)\n",
        "    return self.out_activation(out)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-lRfrurxy54"
      },
      "source": [
        "class RegularBottleneck(nn.Module): #these are the\n",
        "    \n",
        "    def __init__(self,channels,internal_ratio=4,kernel_size=3,padding=0,dilation=1,asymmetric=False,dropout_prob=0,bias=False,relu=True):\n",
        "        super().__init__()\n",
        "\n",
        "        # Check in the internal_scale parameter is within the expected range\n",
        "        # [1, channels]\n",
        "        if internal_ratio <= 1 or internal_ratio > channels:\n",
        "            raise RuntimeError(\"Value out of range. Expected value in the \"\"interval [1, {0}], got internal_scale={1}.\".format(channels, internal_ratio))\n",
        "\n",
        "        internal_channels = channels // internal_ratio\n",
        "\n",
        "        if relu:\n",
        "            activation = nn.ReLU\n",
        "        else:\n",
        "            activation = nn.PReLU\n",
        "\n",
        "        # Main branch - shortcut connection\n",
        "\n",
        "        # 1x1 projection convolution -  reduce the dimensionality\n",
        "        self.ext_conv1 = nn.Sequential(\n",
        "            nn.Conv2d(channels,internal_channels,kernel_size=1,stride=1,bias=bias),\n",
        "            nn.BatchNorm2d(internal_channels),\n",
        "            activation())\n",
        "\n",
        "        # If the convolution is asymmetric we split the main convolution in\n",
        "        # two. Eg. for a 5x5 asymmetric convolution we have two convolution:\n",
        "        # the first is 5x1 and the second is 1x5.\n",
        "        if asymmetric:\n",
        "            self.ext_conv2 = nn.Sequential(\n",
        "                nn.Conv2d(internal_channels,internal_channels,kernel_size=(kernel_size, 1),stride=1,padding=(padding, 0),dilation=dilation,bias=bias),\n",
        "                nn.BatchNorm2d(internal_channels), \n",
        "                activation(),\n",
        "                nn.Conv2d(internal_channels,internal_channels,kernel_size=(1, kernel_size),stride=1,padding=(0, padding),dilation=dilation,bias=bias),\n",
        "                nn.BatchNorm2d(internal_channels),\n",
        "                activation())\n",
        "        else:\n",
        "        #regular or dilated convolution\n",
        "            self.ext_conv2 = nn.Sequential(\n",
        "                nn.Conv2d(internal_channels,internal_channels,kernel_size=kernel_size,stride=1,padding=padding,dilation=dilation,bias=bias), \n",
        "                nn.BatchNorm2d(internal_channels),\n",
        "                activation())\n",
        "\n",
        "        # 1x1 expansion convolution\n",
        "        self.ext_conv3 = nn.Sequential(\n",
        "            nn.Conv2d(internal_channels,channels,kernel_size=1,stride=1,bias=bias),\n",
        "            nn.BatchNorm2d(channels),\n",
        "            activation())\n",
        "\n",
        "        self.ext_regul = nn.Dropout2d(p=dropout_prob)\n",
        "\n",
        "        # PReLU layer to apply after adding the branches\n",
        "        self.out_activation = activation()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Main branch shortcut\n",
        "        main = x\n",
        "\n",
        "        # Extension branch\n",
        "        ext = self.ext_conv1(x)\n",
        "        ext = self.ext_conv2(ext)\n",
        "        ext = self.ext_conv3(ext)\n",
        "        ext = self.ext_regul(ext)\n",
        "\n",
        "        # Add main and extension branches - element-wise addition\n",
        "        out = main + ext\n",
        "\n",
        "        return self.out_activation(out)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2693hzr31xQ"
      },
      "source": [
        "class DownsamplingBottleneck(nn.Module):\n",
        "\n",
        "\n",
        "    def __init__(self,in_channels,out_channels,internal_ratio=4,return_indices=False,dropout_prob=0,bias=False,relu=True):\n",
        "        super().__init__()\n",
        "\n",
        "        # Store parameters that are needed later\n",
        "        self.return_indices = return_indices\n",
        "\n",
        "        # Check in the internal_scale parameter is within the expected range\n",
        "        # [1, channels]\n",
        "        if internal_ratio <= 1 or internal_ratio > in_channels:\n",
        "            raise RuntimeError(\"Value out of range. Expected value in the \"\"interval [1, {0}], got internal_scale={1}. \".format(in_channels, internal_ratio))\n",
        "\n",
        "        internal_channels = in_channels // internal_ratio\n",
        "\n",
        "        if relu:\n",
        "            activation = nn.ReLU\n",
        "        else:\n",
        "            activation = nn.PReLU\n",
        "\n",
        "        # Main branch - max pooling followed by feature map (channels) padding\n",
        "        self.main_max1 = nn.MaxPool2d(2,stride=2,return_indices=return_indices)\n",
        "\n",
        "        # Extension branch - 2x2 convolution, followed by a regular, dilated or\n",
        "        # asymmetric convolution, followed by another 1x1 convolution. Number\n",
        "        # of channels is doubled.\n",
        "\n",
        "        # 2x2 projection convolution with stride 2\n",
        "        self.ext_conv1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels,internal_channels,kernel_size=2,stride=2,bias=bias), \n",
        "            nn.BatchNorm2d(internal_channels), \n",
        "            activation())\n",
        "\n",
        "        # Convolution\n",
        "        self.ext_conv2 = nn.Sequential(\n",
        "            nn.Conv2d(internal_channels,internal_channels,kernel_size=3,stride=1,padding=1,bias=bias),\n",
        "            nn.BatchNorm2d(internal_channels),\n",
        "            activation())\n",
        "\n",
        "        # 1x1 expansion convolution\n",
        "        self.ext_conv3 = nn.Sequential(\n",
        "            nn.Conv2d(internal_channels,out_channels,kernel_size=1,stride=1,bias=bias), \n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            activation())\n",
        "\n",
        "        self.ext_regul = nn.Dropout2d(p=dropout_prob)\n",
        "\n",
        "        # PReLU layer to apply after concatenating the branches\n",
        "        self.out_activation = activation()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Main branch shortcut\n",
        "        if self.return_indices:\n",
        "            main, max_indices = self.main_max1(x)\n",
        "        else:\n",
        "            main = self.main_max1(x)\n",
        "\n",
        "        # Extension branch\n",
        "        ext = self.ext_conv1(x)\n",
        "        ext = self.ext_conv2(ext)\n",
        "        ext = self.ext_conv3(ext)\n",
        "        ext = self.ext_regul(ext)\n",
        "\n",
        "        # Main branch channel padding\n",
        "        n, ch_ext, h, w = ext.size()\n",
        "        ch_main = main.size()[1]\n",
        "        padding = torch.zeros(n, ch_ext - ch_main, h, w)\n",
        "\n",
        "        # Before concatenating, check if main is on the CPU or GPU and\n",
        "        # convert padding accordingly\n",
        "        if main.is_cuda:\n",
        "            padding = padding.cuda()\n",
        "\n",
        "        # Concatenate\n",
        "        main = torch.cat((main, padding), 1)\n",
        "\n",
        "        # Add main and extension branches\n",
        "        out = main + ext\n",
        "\n",
        "        return self.out_activation(out), max_indices\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDmutSxS4ApN"
      },
      "source": [
        "class UpsamplingBottleneck(nn.Module):\n",
        "    def __init__(self,in_channels,out_channels,internal_ratio=4,dropout_prob=0,bias=False,relu=True):\n",
        "        super().__init__()\n",
        "\n",
        "        # Check in the internal_scale parameter is within the expected range\n",
        "        # [1, channels]\n",
        "        if internal_ratio <= 1 or internal_ratio > in_channels:\n",
        "            raise RuntimeError(\"Value out of range. Expected value in the \"\"interval [1, {0}], got internal_scale={1}. \".format(in_channels, internal_ratio))\n",
        "\n",
        "        internal_channels = in_channels // internal_ratio\n",
        "\n",
        "        if relu:\n",
        "            activation = nn.ReLU\n",
        "        else:\n",
        "            activation = nn.PReLU\n",
        "\n",
        "        # Main branch - max pooling followed by feature map (channels) padding\n",
        "        self.main_conv1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=bias),\n",
        "            nn.BatchNorm2d(out_channels))\n",
        "\n",
        "        # Remember that the stride is the same as the kernel_size, just like\n",
        "        # the max pooling layers\n",
        "        self.main_unpool1 = nn.MaxUnpool2d(kernel_size=2)\n",
        "\n",
        "        # Extension branch - 1x1 convolution, followed by a regular, dilated or\n",
        "        # asymmetric convolution, followed by another 1x1 convolution. Number\n",
        "        # of channels is doubled.\n",
        "\n",
        "        # 1x1 projection convolution with stride 1\n",
        "        self.ext_conv1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, internal_channels, kernel_size=1, bias=bias),\n",
        "            nn.BatchNorm2d(internal_channels),\n",
        "            activation())\n",
        "\n",
        "        # Transposed convolution\n",
        "        self.ext_tconv1 = nn.ConvTranspose2d(internal_channels,internal_channels,kernel_size=2,stride=2,bias=bias)\n",
        "        self.ext_tconv1_bnorm = nn.BatchNorm2d(internal_channels)\n",
        "        self.ext_tconv1_activation = activation()\n",
        "\n",
        "        # 1x1 expansion convolution\n",
        "        self.ext_conv2 = nn.Sequential(\n",
        "            nn.Conv2d(internal_channels, out_channels, kernel_size=1, bias=bias),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            activation())\n",
        "\n",
        "        self.ext_regul = nn.Dropout2d(p=dropout_prob)\n",
        "\n",
        "        # PReLU layer to apply after concatenating the branches\n",
        "        self.out_activation = activation()\n",
        "\n",
        "    def forward(self, x, max_indices, output_size):\n",
        "        # Main branch shortcut\n",
        "        main = self.main_conv1(x)\n",
        "        main = self.main_unpool1(main, max_indices, output_size=output_size)\n",
        "\n",
        "        # Extension branch\n",
        "        ext = self.ext_conv1(x)\n",
        "        ext = self.ext_tconv1(ext, output_size=output_size)\n",
        "        ext = self.ext_tconv1_bnorm(ext)\n",
        "        ext = self.ext_tconv1_activation(ext)\n",
        "        ext = self.ext_conv2(ext)\n",
        "        ext = self.ext_regul(ext)\n",
        "\n",
        "        # Add main and extension branches\n",
        "        out = main + ext\n",
        "\n",
        "        return self.out_activation(out)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xd7DpTk4IoTS"
      },
      "source": [
        "class SpatialSoftmax(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SpatialSoftmax, self).__init__()\n",
        "\n",
        "    def forward(self, feature):\n",
        "\n",
        "        feature = feature.view(feature.shape[0], -1, feature.shape[1] * feature.shape[2])\n",
        "        softmax_attention = F.softmax(feature, dim=-1)\n",
        "        return softmax_attention"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ns2BOuFVvwvt"
      },
      "source": [
        "# Buliding the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zMJOLUavo0M"
      },
      "source": [
        "class Enet_SAD(nn.Module):\n",
        "  def __init__(self, binary_seg, embedding_dim, encoder_relu=False, decoder_relu=True, sad=True):\n",
        "    super(Enet_SAD, self).__init__()\n",
        "\n",
        "    self.sad = sad\n",
        "    self.initial_block = InitialBlock(3, 16, relu=encoder_relu)\n",
        "\n",
        "    # Stage 1 share\n",
        "    self.downsample1_0 = DownsamplingBottleneck(16, 64, return_indices=True, dropout_prob=0.01, relu=encoder_relu)\n",
        "    self.regular1_1 = RegularBottleneck(64, padding=1, dropout_prob=0.01, relu=encoder_relu)\n",
        "    self.regular1_2 = RegularBottleneck(64, padding=1, dropout_prob=0.01, relu=encoder_relu)\n",
        "    self.regular1_3 = RegularBottleneck(64, padding=1, dropout_prob=0.01, relu=encoder_relu)\n",
        "    self.regular1_4 = RegularBottleneck(64, padding=1, dropout_prob=0.01, relu=encoder_relu)\n",
        "\n",
        "    # Stage 2 share\n",
        "    self.downsample2_0 = DownsamplingBottleneck(64, 128, return_indices=True, dropout_prob=0.1, relu=encoder_relu)\n",
        "    self.regular2_1 = RegularBottleneck(128, padding=1, dropout_prob=0.1, relu=encoder_relu)\n",
        "    self.dilated2_2 = RegularBottleneck(128, dilation=2, padding=2, dropout_prob=0.1, relu=encoder_relu)\n",
        "    self.asymmetric2_3 = RegularBottleneck(128, kernel_size=5, padding=2, asymmetric=True, dropout_prob=0.1, relu=encoder_relu)\n",
        "    self.dilated2_4 = RegularBottleneck(128, dilation=4, padding=4, dropout_prob=0.1, relu=encoder_relu)\n",
        "    self.regular2_5 = RegularBottleneck(128, padding=1, dropout_prob=0.1, relu=encoder_relu)\n",
        "    self.dilated2_6 = RegularBottleneck(128, dilation=8, padding=8, dropout_prob=0.1, relu=encoder_relu)\n",
        "    self.asymmetric2_7 = RegularBottleneck(128, kernel_size=5, asymmetric=True, padding=2, dropout_prob=0.1, relu=encoder_relu)\n",
        "    self.dilated2_8 = RegularBottleneck(128, dilation=16, padding=16, dropout_prob=0.1, relu=encoder_relu)\n",
        "\n",
        "    # stage 3 binary\n",
        "    self.regular_binary_3_0 = RegularBottleneck(128, padding=1, dropout_prob=0.1, relu=encoder_relu)\n",
        "    self.dilated_binary_3_1 = RegularBottleneck(128, dilation=2, padding=2, dropout_prob=0.1, relu=encoder_relu)\n",
        "    self.asymmetric_binary_3_2 = RegularBottleneck(128, kernel_size=5, padding=2, asymmetric=True, dropout_prob=0.1, relu=encoder_relu)\n",
        "    self.dilated_binary_3_3 = RegularBottleneck(128, dilation=4, padding=4, dropout_prob=0.1, relu=encoder_relu)\n",
        "    self.regular_binary_3_4 = RegularBottleneck(128, padding=1, dropout_prob=0.1, relu=encoder_relu)\n",
        "    self.dilated_binary_3_5 = RegularBottleneck(128, dilation=8, padding=8, dropout_prob=0.1, relu=encoder_relu)\n",
        "    self.asymmetric_binary_3_6 = RegularBottleneck(128, kernel_size=5, asymmetric=True, padding=2, dropout_prob=0.1, relu=encoder_relu)\n",
        "    self.dilated_binary_3_7 = RegularBottleneck(128, dilation=16, padding=16, dropout_prob=0.1, relu=encoder_relu)\n",
        "\n",
        "    # stage 3 embedding\n",
        "    self.regular_embedding_3_0 = RegularBottleneck(128, padding=1, dropout_prob=0.1, relu=encoder_relu)\n",
        "    self.dilated_embedding_3_1 = RegularBottleneck(128, dilation=2, padding=2, dropout_prob=0.1, relu=encoder_relu)\n",
        "    self.asymmetric_embedding_3_2 = RegularBottleneck(128, kernel_size=5, padding=2, asymmetric=True, dropout_prob=0.1, relu=encoder_relu)\n",
        "    self.dilated_embedding_3_3 = RegularBottleneck(128, dilation=4, padding=4, dropout_prob=0.1, relu=encoder_relu)\n",
        "    self.regular_embedding_3_4 = RegularBottleneck(128, padding=1, dropout_prob=0.1, relu=encoder_relu)\n",
        "    self.dilated_embedding_3_5 = RegularBottleneck(128, dilation=8, padding=8, dropout_prob=0.1, relu=encoder_relu)\n",
        "    self.asymmetric_bembedding_3_6 = RegularBottleneck(128, kernel_size=5, asymmetric=True, padding=2, dropout_prob=0.1, relu=encoder_relu)\n",
        "    self.dilated_embedding_3_7 = RegularBottleneck(128, dilation=16, padding=16, dropout_prob=0.1, relu=encoder_relu)\n",
        "\n",
        "    # binary branch\n",
        "    self.upsample_binary_4_0 = UpsamplingBottleneck(128, 64, dropout_prob=0.1, relu=decoder_relu)\n",
        "    self.regular_binary_4_1 = RegularBottleneck(64, padding=1, dropout_prob=0.1, relu=decoder_relu)\n",
        "    self.regular_binary_4_2 = RegularBottleneck(64, padding=1, dropout_prob=0.1, relu=decoder_relu)\n",
        "    self.upsample_binary_5_0 = UpsamplingBottleneck(64, 16, dropout_prob=0.1, relu=decoder_relu)\n",
        "    self.regular_binary_5_1 = RegularBottleneck(16, padding=1, dropout_prob=0.1, relu=decoder_relu)\n",
        "    self.binary_transposed_conv = nn.ConvTranspose2d(16, binary_seg, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "\n",
        "    # embedding branch\n",
        "    self.upsample_embedding_4_0 = UpsamplingBottleneck(128, 64, dropout_prob=0.1, relu=decoder_relu)\n",
        "    self.regular_embedding_4_1 = RegularBottleneck(64, padding=1, dropout_prob=0.1, relu=decoder_relu)\n",
        "    self.regular_embedding_4_2 = RegularBottleneck(64, padding=1, dropout_prob=0.1, relu=decoder_relu)\n",
        "    self.upsample_embedding_5_0 = UpsamplingBottleneck(64, 16, dropout_prob=0.1, relu=decoder_relu)\n",
        "    self.regular_embedding_5_1 = RegularBottleneck(16, padding=1, dropout_prob=0.1, relu=decoder_relu)\n",
        "    self.embedding_transposed_conv = nn.ConvTranspose2d(16, embedding_dim, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "\n",
        "  def generate_attention_type1(self,x1,x2):\n",
        "    #x1: previous encoder feature map\n",
        "    #x2: current encoder feature map\n",
        "    spatial_softmax = SpatialSoftmax()\n",
        "\n",
        "    if x1.size() != x2.size():\n",
        "      x1 = torch.sum(torch.abs(x1), dim=1)\n",
        "      attention1 = x1\n",
        "      x1 = spatial_softmax(x1)\n",
        "      x2 = torch.sum(torch.abs(x2), dim=1, keepdim=True)\n",
        "      x2 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False)(x2)\n",
        "      attention2 = x2\n",
        "\n",
        "      x2 = torch.squeeze(x2, dim=1)\n",
        "      x2 = spatial_softmax(x2)\n",
        "\n",
        "    else:\n",
        "      x1 = torch.sum(torch.abs(x1), dim=1)\n",
        "      attention1 = x1\n",
        "      x1 = spatial_softmax(x1)\n",
        "      x2 = torch.sum(torch.abs(x2), dim=1)\n",
        "      attention2 = x2\n",
        "      x2 = spatial_softmax(x2)\n",
        "\n",
        "    loss = nn.MSELoss(reduction='mean')(x1, x2)\n",
        "    return loss,attention1,attention2\n",
        "\n",
        "  def generate_attention_type2(self,x1,x2):\n",
        "    #x1: previous encoder feature map\n",
        "    #x2: current encoder feature map\n",
        "    spatial_softmax = SpatialSoftmax()\n",
        "\n",
        "    if x1.size() != x2.size():\n",
        "      x1 = torch.sum(x1 * x1, dim=1)\n",
        "      attention1 = x1\n",
        "      x1 = spatial_softmax(x1)\n",
        "\n",
        "      x2 = torch.sum(x2 * x2, dim=1, keepdim=True)\n",
        "      attention2 = x2\n",
        "      x2 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False)(x2)\n",
        "      x2 = torch.squeeze(x2, dim=1)\n",
        "      x2 = spatial_softmax(x2)\n",
        "\n",
        "    else:\n",
        "      x1 = torch.sum(x1 * x1, dim=1)\n",
        "      attention1 = x1\n",
        "      x1 = spatial_softmax(x1)\n",
        "\n",
        "      x2 = torch.sum(x2 * x2, dim=1)\n",
        "      attention2 = x2\n",
        "      x2 = spatial_softmax(x2)\n",
        "\n",
        "    loss = nn.MSELoss(reduction='mean')(x1, x2)\n",
        "\n",
        "    return loss,attention1,attention2\n",
        "\n",
        "  def generate_attention_type3(self,x1,x2):\n",
        "    #x1: previous encoder feature map\n",
        "    #x2: current encoder feature map\n",
        "    spatial_softmax = SpatialSoftmax()\n",
        "\n",
        "    if x1.size() != x2.size():\n",
        "      x1, input_indexes = torch.max(x1 * x1, dim=1)\n",
        "      attention1 = x1\n",
        "      x1 = spatial_softmax(x1)\n",
        "\n",
        "      x2, input_indexes = torch.max(x2 * x2, dim=1, keepdim=True)\n",
        "      x2 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False)(x2)\n",
        "      attention2 = x2\n",
        "\n",
        "      x2 = torch.squeeze(x2, dim=1)\n",
        "      x2 = spatial_softmax(x2)\n",
        "\n",
        "    else:\n",
        "      x1, input_indexes = torch.max(x1 * x1, dim=1)\n",
        "      attention1 = x1\n",
        "      x1 = spatial_softmax(x1)\n",
        "\n",
        "      x2, input_indexes = torch.max(x2 * x2, dim=1)\n",
        "      attention2 = x2\n",
        "      x2 = spatial_softmax(x2)\n",
        "    \n",
        "    loss = nn.MSELoss(reduction='mean')(x1, x2)\n",
        "    return loss,attention1,attention2\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    # Initial block\n",
        "    input_size = x.size()\n",
        "    x = self.initial_block(x)\n",
        "    # Stage 1 share\n",
        "    stage1_input_size = x.size()\n",
        "    x, max_indices1_0 = self.downsample1_0(x)\n",
        "    x = self.regular1_1(x)\n",
        "    x = self.regular1_2(x)\n",
        "    x = self.regular1_3(x)\n",
        "    x_1 = self.regular1_4(x)\n",
        "\n",
        "    # Stage 2 share\n",
        "    stage2_input_size = x_1.size()\n",
        "    x, max_indices2_0 = self.downsample2_0(x_1)\n",
        "    x = self.regular2_1(x)\n",
        "    x = self.dilated2_2(x)\n",
        "    x = self.asymmetric2_3(x)\n",
        "    x = self.dilated2_4(x)\n",
        "    x = self.regular2_5(x)\n",
        "    x = self.dilated2_6(x)\n",
        "    x = self.asymmetric2_7(x)\n",
        "    x_2 = self.dilated2_8(x)\n",
        "\n",
        "    if self.sad:\n",
        "      loss_1, attention_stage1,attention_stage2 = self.generate_attention_type2(x_1, x_2)\n",
        "      \n",
        "    # stage 3 binary\n",
        "    x_binary = self.regular_binary_3_0(x_2)\n",
        "    x_binary = self.dilated_binary_3_1(x_binary)\n",
        "    x_binary = self.asymmetric_binary_3_2(x_binary)\n",
        "    x_binary = self.dilated_binary_3_3(x_binary)\n",
        "    x_binary = self.regular_binary_3_4(x_binary)\n",
        "    x_binary = self.dilated_binary_3_5(x_binary)\n",
        "    x_binary = self.asymmetric_binary_3_6(x_binary)\n",
        "    print(x_binary.shape)\n",
        "    x_3 = self.dilated_binary_3_7(x_binary)\n",
        "    print(x_3.shape)\n",
        "    if self.sad:\n",
        "      loss_2,attention_stage2,attention_stage3 = self.generate_attention_type2(x_2, x_3)\n",
        "\n",
        "    # stage 3 embedding\n",
        "    x_embedding = self.regular_embedding_3_0(x_2)\n",
        "    x_embedding = self.dilated_embedding_3_1(x_embedding)\n",
        "    x_embedding = self.asymmetric_embedding_3_2(x_embedding)\n",
        "    x_embedding = self.dilated_embedding_3_3(x_embedding)\n",
        "    x_embedding = self.regular_embedding_3_4(x_embedding)\n",
        "    x_embedding = self.dilated_embedding_3_5(x_embedding)\n",
        "    x_embedding = self.asymmetric_bembedding_3_6(x_embedding)\n",
        "    x_embedding = self.dilated_embedding_3_7(x_embedding)\n",
        "\n",
        "    # binary branch - deocder\n",
        "    x_binary = self.upsample_binary_4_0(x_binary, max_indices2_0, output_size=stage2_input_size)\n",
        "    print(x_binary.shape)\n",
        "    x_binary = self.regular_binary_4_1(x_binary)\n",
        "    x_binary = self.regular_binary_4_2(x_binary)\n",
        "    \n",
        "    x_binary = self.upsample_binary_5_0(x_binary, max_indices1_0, output_size=stage1_input_size)\n",
        "    x_binary = self.regular_binary_5_1(x_binary)\n",
        "    binary_final_logits = self.binary_transposed_conv(x_binary, output_size=input_size)\n",
        "\n",
        "    # embedding branch - decoder\n",
        "    x_embedding = self.upsample_embedding_4_0(x_embedding, max_indices2_0, output_size=stage2_input_size)\n",
        "    x_embedding = self.regular_embedding_4_1(x_embedding)\n",
        "    x_embedding = self.regular_embedding_4_2(x_embedding)\n",
        "    x_embedding = self.upsample_embedding_5_0(x_embedding, max_indices1_0, output_size=stage1_input_size)\n",
        "    x_embedding = self.regular_embedding_5_1(x_embedding)\n",
        "    \n",
        "    instance_notfinal_logits = self.embedding_transposed_conv(x_embedding, output_size=input_size)\n",
        "\n",
        "    distillation_loss = loss_1 + loss_2\n",
        "\n",
        "    return binary_final_logits, instance_notfinal_logits,distillation_loss , attention_stage1, attention_stage2,attention_stage3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQDwfCF-0UJH"
      },
      "source": [
        "To do List\n",
        "---\n",
        "\n",
        "\n",
        "*   bia encoder ro ye doone ziad kon.. ke too shakheye binary ye encoder bishtar dashe bashi\n",
        "*   attention ro faghat too shakheye mokhtas be segmentation gharar bede\n",
        "* mitooni attentione mokhtas be discriminative ro ham joda gharar bedi ( test kon bebin performance taghiri mikone ya na)\n",
        "* kolan bezar stage0 va stage 1 share bashe baghie mokhtas be khodeshoon bashe\n",
        "* stage 2 ro joda kon\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ue8Bdlrwjc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b158e73-8216-464d-905a-30b81d01a200"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    test_input = torch.ones((8, 3, 256, 512))\n",
        "    net = Enet_SAD(2, 4)\n",
        "    binary_final_logits, instance_notfinal_logits,distillation_loss , attention_stage1, attention_stage2, attention_stage3 = net(test_input)\n",
        "    #x_1 , x_2 =  net(test_input);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 128, 32, 64])\n",
            "torch.Size([8, 128, 32, 64])\n",
            "torch.Size([8, 64, 64, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6VX-Eb9jwIw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}